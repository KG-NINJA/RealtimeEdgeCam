<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<title>Artificial Structure Wireframe (A-1) with Gemma</title>
<style>
body { margin:0; background:#000; overflow:hidden; }
#ui {
  position:fixed;
  top:10px; left:10px;
  color:#0f0;
  font-family:monospace;
  font-size:12px;
  background:rgba(0,0,0,0.6);
  padding:10px;
  z-index: 100;
  border: 1px solid #0f0;
}
/* 日本語コメント: ロボットログ表示用 */
#gemma-log {
  color: #9ff;
  margin-top: 8px;
  font-size: 11px;
  max-height: 120px;
  overflow-y: auto;
  border-top: 1px solid #345;
  padding-top: 5px;
}
video { position: fixed; left: -10000px; }
canvas {
  position: absolute; top: 0; left: 0;
  width: 100vw; height: 100vh;
  pointer-events: none;
  image-rendering: pixelated;
}
</style>
</head>
<body>

<div id="ui">
  <b>A-1 Mapper + FunctionGemma</b><br>
  [M] ML: <span id="ml-stat">OFF</span> | [S] Semantic | [B] Box<br>
  [G] Ask Gemma (Decision) | [R] Robot Sim<br>
  <div id="ml-info">Object: None</div>
  <div id="gemma-log">System Ready. Press [G] to analyze.</div>
</div>

<video id="v" autoplay playsinline muted></video>
<canvas id="c"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<script type="module">
// Hugging Face APIクライアントの読み込み
import { Client } from "https://cdn.jsdelivr.net/npm/@gradio/client/dist/index.min.js";

// --- A-1 Mapper 既存のロジックをモジュール内で再構成 ---
// (ここに元の index.html の定数と変数を統合)
const video = document.getElementById('v');
const canvas = document.getElementById('c');
const ctx = canvas.getContext('2d');
const ui_ml = document.getElementById('ml-info');

const state = {
  mlEnabled: false,
  mlReady: false,
  mlLastClass: '',
  mlLastScore: 0,
  isThinking: false
};

// --- FunctionGemma 接続ロジック ---
async function askGemma() {
  if (state.isThinking) return;
  state.isThinking = true;
  updateLog("Gemma: 思考中...");

  try {
    // ユーザーのSpace URLに合わせて変更してください
    const app = await Client.connect("KGNINJA/FunctionGemmabotdemo-docker");
    
    // 現在の観測結果をプロンプト化
    const observation = state.mlLastClass 
      ? `視界に ${state.mlLastClass} を検知しました (確信度: ${Math.round(state.mlLastScore*100)}%)。行動を決定してください。`
      : "視界に障害物はありません。探索を継続しますか？";

    const result = await app.predict("/predict", { message: observation });
    const response = result.data[0];

    updateLog(`Gemma: ${response}`);
  } catch (err) {
    updateLog("Error: Gemma通信失敗");
    console.error(err);
  } finally {
    state.isThinking = false;
  }
}

function updateLog(msg) {
  const log = document.getElementById('gemma-log');
  log.innerHTML = `<div>${msg}</div>` + log.innerHTML;
}

// --- キーイベントの統合 ---
window.addEventListener('keydown', (ev) => {
  if (ev.code === 'KeyM') {
    state.mlEnabled = !state.mlEnabled;
    document.getElementById('ml-stat').innerText = state.mlEnabled ? "ON" : "OFF";
  }
  // GキーでGemmaに相談
  if (ev.code === 'KeyG') {
    askGemma();
  }
});

// --- 描画ループと robot-control.js の連携 ---
// 別ファイルの robot-control.js を読み込み
import "./robot-control.js"; 

function loop(now) {
  // 元の A-1 描画ロジック (簡略化)
  if (state.mlEnabled && state.mlReady) {
    // COCO-SSD 推論と結果表示の更新
    ui_ml.innerText = `Object: ${state.mlLastClass || 'None'}`;
  }

  // ロボットシミュレーターの更新関数を呼び出し
  if (window.updateRobotControl) {
    window.updateRobotControl(now);
  }
  
  requestAnimationFrame(loop);
}

// カメラ起動とループ開始
navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}}).then(s=>{
  video.srcObject = s;
  requestAnimationFrame(loop);
});

</script>
</body>
</html>
