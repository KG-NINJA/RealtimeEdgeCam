<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>A-1 Robot Vision + Gemma Control</title>
<style>
* { box-sizing: border-box; }
body { margin: 0; padding: 0; background: #000; color: #0f0; font-family: monospace; font-size: 12px; overflow: hidden; width: 100vw; height: 100vh; }
#camera-feed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: #000; z-index: 1; }
#cv { display: block; width: 100%; height: 100%; }
#video { position: fixed; left: -10000px; top: -10000px; width: 1px; height: 1px; opacity: 0; }
#ui { position: fixed; top: 10px; left: 10px; background: rgba(0,0,0,0.9); padding: 12px; border: 2px solid #0f0; color: #0f0; max-width: 420px; z-index: 100; box-shadow: 0 0 10px rgba(0,255,0,0.3); }
.status-line { margin: 5px 0; padding: 3px 0; border-bottom: 1px solid #033; font-size: 11px; }
.status-good { color: #0f0; }
.status-warn { color: #ff0; }
.status-bad { color: #f00; }
.robot-sim { position: fixed; bottom: 10px; right: 10px; border: 2px solid #0f0; background: rgba(0,15,0,0.95); z-index: 50; }
#fps-counter { position: fixed; bottom: 10px; left: 10px; background: rgba(0,0,0,0.8); padding: 5px; border: 1px solid #0f0; z-index: 40; }
</style>
</head>
<body>

<div id="camera-feed"><canvas id="cv"></canvas></div>

<div id="ui">
  <b>‚öôÔ∏è A-1 Robot Vision System</b>
  <div class="status-line">üì∑ Camera: <span id="camera-status">ÂàùÊúüÂåñ‰∏≠...</span></div>
  <div class="status-line">ü§ñ ML-SSD: <span id="ml-status" class="status-warn">OFF (M„Ç≠„Éº)</span></div>
  <div class="status-line">üìä Obstacle: <span id="obs-score">0.00</span></div>
  <div class="status-line">üí≠ Gemma: <span id="gemma-status">STANDBY</span></div>
  <div class="status-line">üöó Robot: <span id="robot-mode" class="status-bad">OFF (R„Ç≠„Éº)</span></div>
  <div class="status-line">üìç Decision: <span id="last-decision" style="font-weight:bold;">-</span></div>
  <div style="margin-top:10px; font-size:10px; color:#0a0;">[R] Robot ON/OFF | [M] ML ON/OFF | [G] Manual Ask</div>
</div>

<div id="fps-counter"><span id="fps">FPS: 0</span></div>
<canvas id="robot-sim" class="robot-sim" width="240" height="240"></canvas>
<video id="video" autoplay playsinline muted></video>

<script src="https://docs.opencv.org/4.x/opencv.js"></script>

<script>
const state = {
  cvReady: false, procW: 320, procH: 240,
  mlEnabled: false, mlReady: false, mlInFlight: false,
  lastObstacleScore: 0, 
  robotEnabled: false, robotX: 120, robotY: 120, robotTheta: 0,
  robotVLin: 0, robotVAng: 0,
  gemmaLastAction: 'WAITING', gemmaNextAt: 0
};

const video = document.getElementById('video');
const cvCanvas = document.getElementById('cv');

function updateStatus(id, text, colorClass) {
  const el = document.getElementById(id);
  if (el) { el.textContent = text; if(colorClass) el.className = 'status-' + colorClass; }
}

/* --- Camera & OpenCV --- */
async function init() {
  const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
  video.srcObject = stream;
  video.onloadedmetadata = () => { video.play(); animate(); };
}

let procRGBA, gray, blur, edges;
function initCV() {
  if (state.cvReady || video.videoWidth === 0) return;
  state.procH = Math.floor(320 / (video.videoWidth/video.videoHeight));
  cvCanvas.width = 320; cvCanvas.height = state.procH;
  procRGBA = new cv.Mat(state.procH, 320, cv.CV_8UC4);
  gray = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC1);
  state.cvReady = true;
  updateStatus('camera-status', 'Ready', 'good');
}

const capCanvas = document.createElement('canvas');
// üî¥ willReadFrequently „Çí true „Å´Ë®≠ÂÆö„Åó„Å¶Ë≠¶Âëä„ÇíËß£Ê∂à
const capCtx = capCanvas.getContext('2d', { willReadFrequently: true });

function runCV() {
  if (!state.cvReady) return;
  capCanvas.width = video.videoWidth; capCanvas.height = video.videoHeight;
  capCtx.drawImage(video, 0, 0);
  let src = cv.matFromImageData(capCtx.getImageData(0, 0, video.videoWidth, video.videoHeight));
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
  cv.Canny(gray, gray, 50, 100);
  cv.resize(gray, procRGBA, new cv.Size(320, state.procH));
  cv.imshow(cvCanvas, procRGBA);
  src.delete();
}

/* --- ML (COCO-SSD) --- */
async function loadML() {
  updateStatus('ml-status', 'Loading...', 'warn');
  const s1 = document.createElement('script'); s1.src = "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs";
  const s2 = document.createElement('script'); s2.src = "https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd";
  document.head.appendChild(s1);
  s1.onload = () => { document.head.appendChild(s2); s2.onload = async () => {
    state.model = await cocoSsd.load();
    state.mlReady = true;
    updateStatus('ml-status', 'Ready', 'good');
  };};
}

async function runML(now) {
  if (!state.mlEnabled || !state.mlReady || state.mlInFlight) return;
  state.mlInFlight = true;
  const preds = await state.model.detect(capCanvas);
  let obj = preds.find(p => p.score > 0.5);
  state.lastObstacleScore = obj ? Math.round(obj.score * 1000) : 0;
  updateStatus('obs-score', (state.lastObstacleScore/1000).toFixed(3));
  state.mlInFlight = false;
}

/* --- Gemma AI Decision --- */
async function askGemma(now) {
  if (!state.robotEnabled || now < state.gemmaNextAt) return;
  state.gemmaNextAt = now + 2000;

  // üî¥ Ë∑ùÈõ¢Ë®àÁÆó„ÇíÂèçËª¢Ôºà„Çπ„Ç≥„Ç¢È´ò„ÅÑ = ÈöúÂÆ≥Áâ©Ëøë„ÅÑ = Ë∑ùÈõ¢„ÅØÂ∞è„Åï„ÅÑÔºâ
  const dist = Math.max(0, 100 - Math.round(state.lastObstacleScore / 10));
  
  updateStatus('gemma-status', 'Thinking...', 'warn');
  try {
    const res = await fetch('https://kgninja-functiongemmabotdemo-docker.hf.space/decide', {
      method: 'POST', headers: {'Content-Type': 'application/json'},
      body: JSON.stringify({ front_distance: dist, speed: state.robotVLin })
    });
    const json = await res.json();
    const match = json.data[0].match(/\{.*\}/s);
    if (match) {
      const d = JSON.parse(match[0]);
      state.gemmaLastAction = (d.action || 'STOP').toUpperCase();
      document.getElementById('last-decision').textContent = state.gemmaLastAction;
      
      // ÊåôÂãï„Å∏„ÅÆÂèçÊò†
      if (state.gemmaLastAction.includes('FORWARD')) { state.robotVLin = 0.6; state.robotVAng = 0; }
      else if (state.gemmaLastAction.includes('LEFT')) { state.robotVLin = 0.1; state.robotVAng = 1.0; }
      else if (state.gemmaLastAction.includes('RIGHT')) { state.robotVLin = 0.1; state.robotVAng = -1.0; }
      else { state.robotVLin = 0; state.robotVAng = 0; }
      
      updateStatus('gemma-status', 'Ready', 'good');
    }
  } catch (e) { updateStatus('gemma-status', 'Error', 'bad'); }
}

/* --- Simulator --- */
function drawSim() {
  const ctx = document.getElementById('robot-sim').getContext('2d');
  ctx.fillStyle = '#001'; ctx.fillRect(0, 0, 240, 240);
  
  // HUD
  ctx.fillStyle = '#0f0'; ctx.font = 'bold 12px monospace';
  ctx.fillText('AI: ' + state.gemmaLastAction, 10, 20);
  ctx.fillText('DIST: ' + (100 - Math.round(state.lastObstacleScore/10)), 10, 35);

  if (state.robotEnabled) {
    state.robotTheta += state.robotVAng * 0.1;
    state.robotX += Math.cos(state.robotTheta) * state.robotVLin * 5;
    state.robotY += Math.sin(state.robotTheta) * state.robotVLin * 5;
    if(state.robotX<0)state.robotX=240; if(state.robotX>240)state.robotX=0;
    if(state.robotY<0)state.robotY=240; if(state.robotY>240)state.robotY=0;
  }

  ctx.save(); ctx.translate(state.robotX, state.robotY); ctx.rotate(state.robotTheta);
  ctx.strokeStyle = '#0f0'; ctx.strokeRect(-8,-8,16,16); ctx.restore();
}

/* --- Main Loop --- */
window.addEventListener('keydown', e => {
  if (e.code === 'KeyM') { state.mlEnabled = !state.mlEnabled; if(state.mlEnabled) loadML(); }
  if (e.code === 'KeyR') { state.robotEnabled = !state.robotEnabled; updateStatus('robot-mode', state.robotEnabled?'ON':'OFF', state.robotEnabled?'good':'bad'); }
  if (e.code === 'KeyG') state.gemmaNextAt = 0;
});

function animate(now) {
  if (!state.cvReady) initCV();
  runCV(); runML(now); askGemma(now); drawSim();
  requestAnimationFrame(animate);
}

cv['onRuntimeInitialized'] = init;
</script>
</body>
</html>
