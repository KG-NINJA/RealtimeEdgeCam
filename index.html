<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8" />
<title>Robot Decision Demo (Camera → HF)</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<style>
  body {
    margin: 0;
    background: #000;
    color: #0ff;
    font-family: monospace;
  }
  #video {
    position: fixed;
    right: 10px;
    bottom: 10px;
    width: 240px;
    border: 1px solid #345;
    opacity: 0.9;
  }
  #overlay {
    position: fixed;
    left: 10px;
    top: 10px;
    background: rgba(0,0,0,0.6);
    padding: 8px;
    border: 1px solid #0af;
  }
  #log {
    white-space: pre-wrap;
    font-size: 12px;
  }
</style>
</head>

<body>

<div id="overlay">
  <div>Robot Decision Demo</div>
  <div>G: Ask Gemma</div>
  <div id="log"></div>
</div>

<video id="video" autoplay playsinline muted></video>
<canvas id="grab" width="160" height="120" style="display:none;"></canvas>

<script>
/* =========================
   設定
========================= */
const DECISION_API =
  "https://KGNINJA-FunctionGemmabotdemo-docker.hf.space/decide";

/* =========================
   要素取得
========================= */
const video = document.getElementById("video");
const grab = document.getElementById("grab");
const gctx = grab.getContext("2d");
const logEl = document.getElementById("log");

/* =========================
   ログ表示
========================= */
function log(msg, obj) {
  logEl.textContent =
    msg + (obj ? "\n" + JSON.stringify(obj, null, 2) : "");
}

/* =========================
   カメラ起動（ユーザー操作後）
========================= */
async function startCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "environment" },
    audio: false
  });
  video.srcObject = stream;
  await video.play();
  log("Camera started");
}

document.body.addEventListener("click", startCamera, { once: true });

/* =========================
   映像 → 数値化（最小）
   中央輝度 = front_distance
========================= */
function computeFrontDistance() {
  gctx.drawImage(video, 0, 0, grab.width, grab.height);

  const cx = grab.width / 2 - 5;
  const cy = grab.height / 2 - 5;
  const img = gctx.getImageData(cx, cy, 10, 10);

  let sum = 0;
  for (let i = 0; i < img.data.length; i += 4) {
    sum += img.data[i]; // R値
  }
  const avg = sum / (img.data.length / 4);
  return avg / 255; // 0.0〜1.0
}

/* =========================
   観測データ構築
========================= */
function buildObservation() {
  return {
    front_distance: computeFrontDistance(),
    speed: 0.0
  };
}

/* =========================
   Gemma に判断させる
========================= */
async function askGemma() {
  const obs = buildObservation();
  log("SEND TO GEMMA", obs);

  try {
    const res = await fetch(DECISION_API, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(obs)
    });

    const decision = await res.json();
    log("GEMMA RESPONSE", decision);
  } catch (e) {
    log("ERROR", String(e));
  }
}

/* =========================
   Gキーで送信
========================= */
window.addEventListener("keydown", (e) => {
  if (e.code === "KeyG") {
    askGemma();
  }
});
</script>

</body>
</html>
