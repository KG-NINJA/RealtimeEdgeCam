<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8">
<title>Camera + COCO-SSD + Gemma</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<style>
  body { margin:0; background:#000; color:#0ff; font-family:monospace; }
  video {
    position: fixed;
    right: 10px;
    bottom: 10px;
    width: 240px;
    border: 1px solid #345;
  }
  canvas {
    position: fixed;
    left: 0;
    top: 0;
  }
  #hud {
    position: fixed;
    left: 10px;
    top: 10px;
    background: rgba(0,0,0,.6);
    padding: 8px;
    border: 1px solid #0af;
    white-space: pre-wrap;
    font-size: 12px;
  }
</style>
</head>

<body>

<div id="hud">Loading...</div>

<video id="video" autoplay playsinline muted></video>
<canvas id="canvas"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<script>
/* =======================
   設定
======================= */
const DECISION_API =
  "https://KGNINJA-FunctionGemmabotdemo-docker.hf.space/decide";

/* =======================
   要素
======================= */
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const hud = document.getElementById("hud");

canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

let model = null;
let lastDetections = [];

/* =======================
   カメラ起動（クリック必須）
======================= */
async function startCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "environment" },
    audio: false
  });
  video.srcObject = stream;
  await video.play();
  hud.textContent = "Camera started\nLoading COCO-SSD...";
  model = await cocoSsd.load();
  hud.textContent = "COCO-SSD ready\nPress G to ask Gemma";
}

document.body.addEventListener("click", startCamera, { once: true });

/* =======================
   検出ループ
======================= */
async function detectLoop() {
  if (model && video.videoWidth > 0) {
    lastDetections = await model.detect(video);
  }
  requestAnimationFrame(detectLoop);
}
detectLoop();

/* =======================
   描画ループ
======================= */
function draw() {
  ctx.clearRect(0,0,canvas.width,canvas.height);

  if (video.videoWidth > 0) {
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  }

  ctx.strokeStyle = "#0f0";
  ctx.lineWidth = 2;
  ctx.font = "16px monospace";

  for (const d of lastDetections) {
    const [x,y,w,h] = d.bbox;
    ctx.strokeRect(x, y, w, h);
    ctx.fillText(
      `${d.class} ${(d.score*100).toFixed(1)}%`,
      x, y > 20 ? y-5 : y+20
    );
  }

  requestAnimationFrame(draw);
}
draw();

/* =======================
   危険度 → front_distance
======================= */
function computeFrontDistance() {
  if (lastDetections.length === 0) return 1.0;

  let danger = 0;
  for (const d of lastDetections) {
    if (["person","chair","table","tv","laptop"].includes(d.class)) {
      danger = Math.max(danger, d.score);
    }
  }
  return 1.0 - danger;
}

/* =======================
   Gemma に送信
======================= */
async function askGemma() {
  const front = computeFrontDistance();
  const payload = {
    front_distance: front,
    speed: 0
  };

  hud.textContent =
    "SEND TO GEMMA\n" + JSON.stringify(payload, null, 2);

  try {
    const res = await fetch(DECISION_API, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload)
    });
    const json = await res.json();
    hud.textContent =
      "GEMMA RESPONSE\n" + JSON.stringify(json, null, 2);
  } catch (e) {
    hud.textContent = "ERROR\n" + e;
  }
}

/* =======================
   Gキー
======================= */
window.addEventListener("keydown", e => {
  if (e.code === "KeyG") askGemma();
});
</script>

</body>
</html>
